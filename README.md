# PathFinder: Real-Time Object Recognition and Navigation Assistance for the Blind

## Introduction

This project proposes the development of a mobile application designed to leverage computer vision and object recognition technology. The app aims to provide blind users with real-time information about their surroundings, enhancing their ability to navigate safely and independently.

## Project Goal

The primary goal is to develop a user-friendly and accessible mobile application that empowers visually impaired individuals by providing real-time object recognition and navigation assistance. The app will offer audio descriptions of objects in the user's environment, aiding in safe and independent navigation.

## Methodology

The methodology involves using the smartphone camera to capture live video, which is then streamed to a server. The server analyzes the image frames to detect objects and sends the results back to the mobile application. A text-to-speech module generates audio descriptions for the user.

The entire process operates seamlessly on the user's mobile device. When the app is launched, the smartphone camera is activated, allowing the user to position the phone for optimal camera view, such as in a front pocket. The real-time video is streamed to the server for object recognition and analysis. The server's results are transmitted back to the application, where text-to-speech functionality conveys the information to the user through earphones.

## Key Functionalities

- Real-time Video Processing: The app captures and processes live video for object recognition.

- Object Recognition: Utilizing deep learning models, the app identifies objects within the video frames.

- Audio Description Generation: The app generates concise audio descriptions of identified objects using text-to-speech technology.

- Navigation Assistance: Future functionalities may include obstacle detection and path guidance to further aid in navigation.


## Usage

- Launch the application on your mobile device.

- Ensure the smartphone camera is activated and positioned for an optimal view.

- The app will begin capturing and processing live video.

- Detected objects will be identified, and audio descriptions will be generated and played through the earphones.

## Contributing
Contributions are welcome! Please read the contribution guidelines for more information.